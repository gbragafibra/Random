{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d377b2ce",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4091fef",
   "metadata": {},
   "source": [
    "A little exploration of some neural network frameworks, hoping to grasp more specifically recurrent neural networks, and reservoir computing, specially those directed towards physical reservoir computing, using in vitro/in vivo systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453837cb",
   "metadata": {},
   "source": [
    "One of the central interests comes from the prediction and reconstruction of time-series. A very nice characteristic of in vitro/in vivo systems, is that they have been under the \"evolutionary test\" for a reasonable amount of time, such that emerging from resource scarce conditions, majority of times, if not all, a bet-hedging scheme appears, along with majority of substrates in this respective system being multi-functional. This out of itself is pressed by a necessity not to optimize for what we perceive to be a single metric, but to minmax for an enormous set of them. After that, what would be an individual with its own incentives, is usually merged with other ones of the same scale, resulting in larger-scale networks that inherently constrain the state-space exploration of its constituents. \n",
    "All of this to say: There's lots of non-linear dynamics to be harvested and to be used as a reservoir for time-series prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd8bde",
   "metadata": {},
   "source": [
    "Furthermore, when talking about convergence to a certain state, or for that manner a set of them, taking into account the multi-functional charactertistic that majority of components take, we'll always have a minmax scheme. Or atleast something that is perceived as such, such that the feedback loops respective to such system being considered don't have enough or perfect resolution, for such systems to be considered fully deterministic. That, and what follows from game-theory after that: Exploit to the extent of not being exploited to failure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af8e98",
   "metadata": {},
   "source": [
    "### On finding other abstractions in biology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d0360",
   "metadata": {},
   "source": [
    "Perhaps we can state that some of the abstractions we have found successful in biology are themselves general principles. However, how many of these abstractions can we really say pertrain to the biological world. There's fundamentally no organism being described. Perhaps we don't have the mathematics for it yet.\n",
    "As another contender, we might instead dwelve into a relational approach, instead of relying in a mechanistic one, with category theory. However, again, is this approach not inherently too hard bounded? The moment we say that a certain object pertrains to a specific set, or to a finite amount of them, encapsulating some function, and then building on top of it some category, functor, or natural transformation, we are inherently missing the point. In the biological world, everything goes. In the sense that even if some protein has a known function (high correlation mechanism), it still partakes in the cellular milieu, and as such, is associated with every other perceptible \"function\", or for that manner every other that we can abstract.\n",
    "Are there other approaches to be discovered, that we have funnelled ourselves out of? For example, regarding heredity of form relative to multicellular systems. Who cares about preservation of genome, if they preserve the same geometry. What about the amount of heat released, and associated fluctuations? Can we link the thermodynamic/information-theoretic approach to biology?\n",
    "The problem is that physics seems indeed to be the exception, and biology the rule (this in terms of what types of systems and the way we describe their behaviour in each field).\n",
    "How can I form reasonable enough abstractions about systems with an unbelievable amount of compression? \n",
    "And then take into account looping realization that we aren't spectators. It also applies to us, whatever type of dynamics and constraints of exploration that you see across Nature, also limit our formalizations and abstractions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe9f5e-c4f0-43e7-b4d0-2a600cd789a6",
   "metadata": {},
   "source": [
    "#### Small notes on [Evolution \"On Purpose\": Teleonomy in Living Systems](https://direct.mit.edu/books/oa-edited-volume/5634/Evolution-On-Purpose-Teleonomy-in-Living-Systems) \n",
    "\n",
    "Whilst a good part of biology as a whole can be stated to be devoid of the organism, as pertaining to having a good theory of emergence relying on concepts like autopoiesis, autocatalysis, closure of constraints, and any other concept that tries to model the relation: constraints of a system dictate the dynamics, and the dynamics lead to an update of the constraints; it is nonetheless even more of an insormountable task given that we are not spectators. We are ourselves wholes, and parts at the same time, and as such our perceptions and through extention our formal systems (or the ones we can build) are themselves at mercy of an evolutionary process that usually tends to benefit robustness, in this case of larger scale networks, these ones enabling and perpetuating the conditions that gave rise to us (here largely thinking that a good chunck of bad options, has been selected out through evolutionary funnels).\n",
    "\n",
    "Regarding the concept of teleonomy, we can perhaps state that it exists such that living systems have an internal \"purposiveness\" or a collection of goal-states they act towards, and usually being characteristic of non-equilibrium systems. Also, atleast on this last remark, on long evolutionary scales, systems that have a better perception, and that themselves develop a more robust teleonomy, are going to be selected, as they can better model a world with other such systems they need to cooperate, compete, and merge with. Furthermore, living systems literally build themselves, such that fundamentally the biggest problem in addressing them, is mimicking and building a system that rebuilds over and over the perception of its own boundaries, whilst using a very complex internal antecipation system. This type of antecipation would rely on every part of the whole system, also being a whole itself with its own incentives (or goal-states), such that small changes in degrees of freedom in smaller parts would be allocated and propagated throughout a larger whole, resulting in the larger whole morphing the state-space of the smaller wholes so as to meet its own incentives. An important divergence from modern evolutionary synthesis, is that it's easier to change a system through exploration of larger-scale modules, than through micromanaging lower-scale ones (wrt majority of cases of course).\n",
    "\n",
    "It is also perhaps important to note that this notion of internal \"purposiveness\" can also be seen merely through an analogue of state-space evolution, although only if seen by an \"observer-system\" that shares low to no information of the respective internal model. In fact, any type of dynamical system, specially non-equilibrium ones, can be put through this lens, and come out as having an internal drive, or set of goal-states (states it oscillates around and converges to). The huge problem on relying solely in describing the state-space of biological systems and using it for prediction, is that pre-stating such state-space and saying it predicts something reasonable, is usually the same as saying that such system stopped in time, with no other influences affecting it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56961414-3cb1-4d2e-bae5-c7e4a04b9f66",
   "metadata": {},
   "source": [
    "### Regarding Intelligence\n",
    "An intelligent system would perhaps first and foremost be characterized by autopoiesis, by the capacity to literally build itself. Such systems, even ones with larger-scale organization, like social ones, are themselves intelligent, given that they have constituents showing these capacities. Each constituent, and consequently each sub-network formed by combinatorial relations between these constituents will also have autopoietic capacities, and respectively have its own incentives. This is where intelligence stems from. Initially, larger-scale networks, will seem to lack these capacities, but as they form more robust constraints, limiting the state-space exploration of its constituents, such capacities will emerge, through self-preservation. As such, overtime they will have more refined control over the update of their own boundaries. \n",
    "\n",
    "If from the start, smaller parts forming the larger whole lack these capacities, the \"emerging\" larger-scale system, will not be considered intelligent. If there is no coarse-graining between scales, if there is micromanaging of lower-scale networks, there probably won't be any type of intelligence to such system being described. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97c41b-63bc-4b07-8297-44b96116600b",
   "metadata": {},
   "source": [
    "### Regarding memory\n",
    "If we take memory to be the capacity to converge to a state or to a set of them, general dynamical systems are not so much different than biological systems. Both these systems have their state space evolution depending on the respective input applied. However, in biological systems there's a much larger combinatorial allocation possible, given coarse-graining over scales. Not only are those memories that are realized by the current state space kept, but also those that are in \"vicinity\" of such state space. And given the amount of variance (resulting from multiple agents with their own incentives, forming a larger scale system), there's a huge set of memories being kept, that wildly surpasses the type of memory allocation that we have in digital systems. Just imagine other types of architechtures that wouldn't rely on micromanaging memory preservation. This huge set of memories being kept, that at a certain point could simply be perceived as \"learned behaviours\" (as opposed to simple mechanism, in lower scale systems, for example considering molecular biology) in larger scale systems, is therefore at a reasonable reach given a few \"inputs\".\n",
    "\n",
    "Everything is useful in the biological world, even \"waste\" heat resulting from some enzimatic reactions leading to increased diffusion rates for other molecules. There no such thing as a non-relation. Everything is related. A measurement is a relation. As such, what's missing in biology is precisely the study of the organism.\n",
    "\n",
    "Furthermore, considering both general dynamical systems and biological ones, to be in a scenario where they are deprived from external inputs, the state-space evolution of these biological systems is so much richer and more complex, that they actually look as if they have an \"internal drive\", or teleonomy. There is an appearance of exploration, that is characterized by an updating of the system's constraints, without relying heavily on external inputs. This is where intelligence presumably stems from. The capacity to make use of every attribute of the system, leading to a robust exploration capability. I would presume intelligence is actually linked to this type of memory. One that is highly non-rigid, given that for a respective input there's propagation and allocation of it over a great range of the total degrees of freedom of the system. Such is the case, that traditional evolutionary synthesis would be put to the corner, given the huge magnitude of adaption capabilities demonstrated by biological systems, specially when dealing with novel perturbations, being largely unexplainable by simply refering to memory allocation in DNA, RNA, cytoskeleton components, etc (and scaling up the dimensions of the system). These are what we can reasonably abstract. What about those we can't? Do we simply ignore them? \n",
    "\n",
    "Regarding what was mentioned about teleonomy, the type of behaviour being described is the same, either if seen by a process philosophy lense, or one alligned more with a material-deterministic one. It's the same thing being described by two different perspectives, and we shouldn't \"choose a side\" here. Whatever works, works. There's something very ironic about clinging so much to a single perspective, given that the perception of the \"sublime\" is largely unachievable. There's too much evolutionary momentum, and too much compression, for us to lose so much time not exploring every perspective we have at our reach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d088d63-8326-42ab-930a-c2b5ce1f2182",
   "metadata": {},
   "source": [
    "### More on memory\n",
    "\n",
    "If we take, again, memory to be the capacity to converge to a state, or to a set of them, each system, as a whole and as constituent, of a larger scale one, will have a \"goal-state\", $\\Delta$, it gravitates towards. Furthermore, if we are to abstract such dynamics in a landscape, such system is invariably decreasing its suprisal (regarding free energy principle) given its environment. As such, the respective system would inherently be in a location of its state-space, where suprisal is minimized (where its dynamics most accurately predict the environment it is in). Moreover, such system would probably have dissipation, by heat released, as $\\Delta Q \\propto \\epsilon_{\\Delta}$. Having heat released proportional to the distance to its \"goal-state\", $\\epsilon_{\\Delta}$. This is for a single scale. However, one ought to see this as a multi-agent relation. Where each agent has it own \"goal-state\" $\\Delta$. Furthermore, systems of larger-scale will inherently morph the state-space of its constituents so as to meet their own goal-states.\n",
    "\n",
    "Intelligence would presumably be linked to the capacity of generalization. In this case, such would represent having low-transition costs, between funnels in the landscape. In other words, no hard convergence to a set of states. To the point that, even with internal dynamics of its constituents, and little external inputs, a larger scale system would be able to adapt robustly with little effort to new pertubations. \n",
    "\n",
    "As such, one would presumably see $\\Delta Q \\propto m^{\\alpha}$, with $\\alpha < 1$. As systems increase in mass, they would invariably have to coarse-grain over scales, if they are to be considered evolutionary successfull (and emerging out of resource-scarcity).\n",
    "\n",
    "On this matter systems that employ micro-managing of lower-scales would be at a disadvantage, as they would tipically hard converge to a set of states, losing generality. \n",
    "\n",
    "Moreover, abstractions like hardware and software, presumably have problems when applied to biological systems, given that in these systems, every constituent likely serves both roles. If we can say, likely serves both structural and functional roles, in every relation we can abstract."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
